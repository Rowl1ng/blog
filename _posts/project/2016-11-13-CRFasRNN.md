---
layout: post
title: CRF as RNN
category: project
description: 在CNN之后的probability inference。
---

**《Conditional Random Fields as Recurrent Neural Networks》**

## 理论部分

### 关于概率图模型

Conditional Random Fields：Markov Random Fields 的变种。
![CRF][1]
假设图$$G=(V,E)$$，其中$$V={X_1,X_2,\dots,X_N}$$，全局观测为$$I$$。使用Gibbs分布，$$(I,X)$$可被模型为CRF

$$
P(X=x|I)=\frac 1{Z(I)}exp(-E(x|I))
$$
$$ 
E(x)=\sum _i \varphi(x_i)+\sum _{i<j} \varphi_p(x_i.x_j)
$$

$$\varphi_p(x_i.x_j)$$是对$$i$$、$$j$$同时分类成$$x_i$$、$$x_j$$的能量。

将 label assignment problem 转化为 probability inference problem ，融入对相似像素的**标签一致性**的推断。

从 coarse 到 fine-grained segmentation ，主要用来弥补 CNN 在 pixel-level labeling tasks 上的不足。

那么这篇论文最重要的工作就是end-to-end训练,CRF的error derivative直接传到了CNN。而CNN负责产生unary potential,至少intuitively上更合理，实验效果也确实更好。

这里我们先回顾一下条件随机场图像分割能量函数的构造：定义隐变量Xi为像素点i的分类标签，它的取值范围是就是我们要分类的语义标签L={l1,l2,l3……}；Yi为每个随机变量Xi的观测值，也就是每个像素点的颜色值。条件随机场的图像语义分割的目标就是：通过观测变量Yi，推理出潜变量Xi的对应类别标签。

> 很像是NLP里的句子成分分析，HMM，下面的是主谓宾，上层就是它的观测，对应的句子成分。最后的训练效果也是根据句子本身得到各个成分的主谓宾关系，而且输出的是树状模型。

对于一张图像来说，我们把它看成图模型G=(V,E)，图模型的每个顶点对应一个像素点，即V={X1，X2，……Xn}。对于边来说，

(1)如果是稀疏条件随机场，那么我们构造图模型的边集合E就是：每对相邻的像素点间可以构造一条边。当然除了4邻域构造边之外，你也可以用8邻域模型。

(2)全连接条件随机场与稀疏条件随机场的最大差别在于：每个像素点都与所有的像素点相连接构成连接边。这就恐怖了，如果一张图像是100*100，那么就相当于有10000个像素点，因此如果采用全连接条件随机场的话，那么就会构造出约10000*10000条边。如果图像大小再大一些，那么就会变得非常恐怖，普通条件随机场推理算法，根本行不通。好在文献《Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials》给出了快速推理算法。接着我们就简单讲解具体的求解算法。

---
输入图像：
$$
x=\{x_1,\dots,x_P\}
$$
$P$为像素数。

目标输出：
$$
y=\{y_1,\dots,y_B\},y_i \in L=\{l_1,l_2,\dots,l_L\}
$$
因为我们判断的是每一方格**是不是**裂缝。因此这里的标签$L$只有两种。$y_i$即为第$i$个方格的标签。

- 结构：
    - CNN : **unary** potential
    - CRF : **binary** potential

- inference method
    - **back propagation** : 论文中使用的是**SGD**来进行反向传播
    - **minibatch** :训练时可以用一整张图，也可以用多张图作为 


### Mean-field = CNN + softmax

1. 首先初始化：对每个像素上的所有label做softmax,产生的误差可以直接传递给unary potential inputs

> sofmax

2. Message passing:
    - Guassian filters:
        - coefficient直接从像素位置、RGB信息中来，反映和其他像素的关联程度
        - CRF是potentially fully connected ，每个filter的receptive field都是整张图，强制法实现不可行
            -  Andrew Adams et al所提出的基于[**Pemutohedral Lattice**][2]的滤波实现，$O(n)$
                - splat
                - blur
                - slice
    - 误差反向通过filter，逆转blur阶段filter的顺序，$O(n)$
    - 2 Guassian Kernel：Bilateral filter 和Spatial filter两种滤波器
3. 为每个类别计算filter输出的weighted sum 
    - spatial kernel和bilateral kernel权重独立于每个类别，因为和识别对象有关
4. Compatibility Transform
    - $\mu (l,l')$：两个标签纸间的compatibility
        - fixed penalty，如果相似像素标签不同
        - 可看作是卷积操作，学习filter的参数就是在学习函数$\mu$
5. unary-compatibility transform
    - 未引入其他参数，无查直接传递给两个输入，注意符号
6. Normalization：softmax
    - softmax的反向传播
                
#### Pemutohedral Lattice

![此处输入图片的描述][3]

![此处输入图片的描述][4]

### Iterable Mean-field = RNN    
    
- $Q_in$：an estimation marginal probability from the previous iteration
$$
f_{\theta}(U,Q_{in},I) \\
\theta=\{\omega^{(m)},\\
\mu(l,l')\},m\in \{1,\dots,M\},l,l' \in \{l_1,\dots,l_L\}
$$

这个RNN的结构，假设迭代T次：

- t=0,使用softmax（U）来初始化
- t>1,每轮$f_{\theta}$中的$Q_{in}$为上一轮输出
- 输出$Y$
- 学习算法：BP through time
    - 5次迭代即可收敛，再增加可能导致vanishing和exploding gradient problems。
: 实现Bilateral filter 的bilateral_lattices_和实现Spatial filter的spatial_lattice

## Caffe上的实现

Caffe 是由伯克利大学视觉和学习中心开发的一种深度学习框架。在视觉任务和卷积神经网络模型中，Caffe 格外受欢迎且性能优异


### 自己写Python层作为输入层

road_layer.py
```
self.x = np.load(os.path.join(CACHE_PATH, 'x_{}.npy'.format(self.split)))
self.y = np.load(os.path.join(CACHE_PATH, 'y_{}.npy'.format(self.split)))
```
- setup()是类启动时该做的事情，比如层所需数据的初始化。 
- reshape()就是取数据然后把它规范化为四维的矩阵。每次取数据都会调用此函数。 
- forward()就是网络的前向运行，这里就是把取到的数据往前传递，因为没有其他运算。 
    - assign output
    - pick next input
- backward()就是网络的反馈，data层是没有反馈的，所以这里就直接pass。

### 生成训练网络

net.py生成网络结构文件

```
    n.data, n.label = L.Python(module='road_layer', layer='ROADSegDataLayer',
            ntop=2, param_str=str(pydata_params))

    # the base net
    n.conv1_1, n.relu1_1 = conv_relu(n.data, 32, ks=5)
    n.conv1_2, n.relu1_2 = conv_relu(n.relu1_1, 32, ks=5)
    n.pool1 = max_pool(n.relu1_2)

    n.conv2_1, n.relu2_1 = conv_relu(n.pool1, 64)
    n.conv2_2, n.relu2_2 = conv_relu(n.relu2_1, 64)
    n.pool2 = max_pool(n.relu2_2)

    n.conv3_1, n.relu3_1 = conv_relu(n.pool2, 128)
    n.conv3_2, n.relu3_2 = conv_relu(n.relu3_1, 128)
    n.pool3 = max_pool(n.relu3_2)

    n.conv4_1, n.relu4_1 = conv_relu(n.pool3, 256)
    n.conv4_2, n.relu4_2 = conv_relu(n.relu4_1, 256)
    # n.conv4_3, n.relu4_3 = conv_relu(n.relu4_2, 512)
    n.pool4 = max_pool(n.relu4_2)

    n.conv5_1, n.relu5_1 = conv_relu(n.pool4, 256)
    n.conv5_2, n.relu5_2 = conv_relu(n.relu5_1, 256)
    # n.conv5_3, n.relu5_3 = conv_relu(n.relu5_2, 512)
    n.pool5 = max_pool(n.relu5_2)

    n.score = conv(n.pool5, 1)
    n.loss = L.SigmoidCrossEntropyLoss(n.score, n.label)
    # n.loss = L.MultiStageMeanfield()
```
分别为一次导入的图片个数，channel，heigth ，width。

### Solver 优化

此处的SGD指mini-batch gradient descent，关于batch gradient descent, stochastic gradient descent, 以及 mini-batch gradient descent的具体区别就不细说了。现在的SGD一般都指mini-batch gradient descent。
SGD就是每一次迭代计算梯度，然后对参数进行更新，是最常见的优化方法了。
此处主要说下SGD的缺点：（正因为有这些缺点才让这么多大神发展出了后续的各种算法）

- 选择合适的learning rate比较困难
- 对所有的参数更新使用同样的learningrate。对于稀疏数据或者特征，有时我们可能想更新快一些对于不经常出现的特征，对于常出现的特征更新慢一些，这时候SGD就不太能满足要求了
- SGD容易收敛到局部最优，并且容易被困在鞍点



损失平面等高线：

![损失平面等高线][5]

在鞍点处的比较：

![在鞍点处的比较][6]

在Deep Learning中，往往loss function是非凸的，没有解析解，我们需要通过优化方法来求解。solver的主要作用就是交替调用前向（forward)算法和后向（backward)算法来更新参数，从而最小化loss，实际上就是一种迭代的优化算法。

到目前的版本，caffe提供了六种优化算法来求解最优参数，在solver配置文件中，通过设置type类型来选择。
  在训练多通道图片时，此处最好需要有一个meanfile参数。.binaryproto
  
```
 train_net: "train.prototxt"
# train_net: "TVG_CRFRNN_new_deploy.prototxt"
test_net: "val.prototxt"
test_iter: 16
test_interval: 500
base_lr: 5e-4
lr_policy: "fixed"
momentum: 0.99
type: "Adam"
weight_decay: 0.0005
display: 100
max_iter: 1000
snapshot: 1000
snapshot_prefix: "snapshot/train"
solver_mode: GPU
```

This parameter indicates how the learning rate should change over time. This value is a quoted string.

1. Options include:

- "step" - drop the learning rate in step sizes indicated by the gamma parameter.
- "multistep" - drop the learning rate in step size indicated by the gamma at each specified stepvalue.
- "fixed" - the learning rate does not change.
- "exp" - gamma^iteration
- "poly" -
- "sigmoid" -

### 训练caffemodel

```
../CRFasRNN-merge/caffe-master/build/tools/caffe train -solver solver.prototxt

```

```
solver = caffe.SGDSolver('models/bvlc_reference_caffenet/solver.prototxt')
```
### 整合crfasrnn

`net.params` : a vector of blobs for **weight** and **bias** parameters

`net.params['conv1_1'][0]` contains the weight parameters, an array of shape (32, 1, 5, 5) net.params['conv'][7] contains the bias parameters, an array of shape (3,)

```
solver = caffe.SGDSolver('solver.prototxt')
solver.net.copy_from('pretrained_param_file')
[...]

## control layer's initialization
halt_training = False
for layer in solver.net.params.keys():
  for index in range(0, 2):
    if len(solver.net.params[layer]) < index+1:
      continue

    if np.sum(solver.net.params[layer][index].data) == 0:
      print layer + ' is composed of zeros!'
      halt_training = True

if halt_training:
  print 'Exiting.'
  exit()
```

To launch **one step** of the gradient descent, that is a forward propagation, a backward propagation and the update of the net params given the gradients (update of the net.params[k][j].data) :
```
solver.step(1)
```

    
### MultiStageMeanfieldLayer



## 细节

### Loss Function

- 训练时迭代5，测试时迭代10
- Loss function：
    - 训练时：log likelihood
    - 测试时：average IU

average intersection over union(IU)

### Normalization techniques

rectified linear unit (ReLU)

## 环境搭建

安装python依赖库：

    sudo pip install -r requirements.txt

### 测试

    #!/bin/bash
    
    TOOLS=../../caffe/build/tools
    WEIGHTS=TVG_CRFRNN_COCO_VOC.caffemodel
    SOLVER=TVG_CRFRNN_new_solver.prototxt
    
    $TOOLS/caffe train -solver $SOLVER -weights $WEIGHTS -gpu 0

### Debug

1. cuda
```
    libcudart.so.7.0: cannot open shared object file: No such file or directory
```
```
    sudo ldconfig /usr/local/cuda-7.5/lib64
```
2. Python
```
    Unknown layer type: Python (known types: AbsVal, Accuracy, ArgMax, BNLL, Concat, ContrastiveLoss, Convolution, Crop, Data, Deconvolution, Dropout, DummyData, Eltwise, Embed, EuclideanLoss, Exp, Filter, Flatten, HDF5Data, HDF5Output, HingeLoss, Im2col, ImageData, InfogainLoss, InnerProduct, LRN, Log, MVN, MemoryData, MultiStageMeanfield, MultinomialLogisticLoss, PReLU, Pooling, Power, ReLU, Reduction, Reshape, SPP, Sigmoid, SigmoidCrossEntropyLoss, Silence, Slice, Softmax, SoftmaxWithLoss, Split, TanH, Threshold, Tile, WindowData)
```
修改Makefile.config
```
WITH_PYTHON_LAYER := 1
```
重新make caffe
```
rm -rf ./build/*
make all -j8
```
 8 is the number of parallel threads for compilation (a good choice for the number of threads is the number of cores in your machine).
 
2.1 build errors:undefined cv::imread() cv::imencode() ...
```
cmake
```


  [1]: http://img.blog.csdn.net/20160423111733218
  [2]: http://blog.csdn.net/xuanwu_yan/article/details/7962508
  [3]: http://img.my.csdn.net/uploads/201209/21/1348218477_3540.png
  [4]: http://img.my.csdn.net/uploads/201211/03/1351909905_5548.png
  [5]: http://img.blog.csdn.net/20160824161755284
  [6]: http://img.blog.csdn.net/20160824161815758
  [7]: http://blog.csdn.net/xuanwu_yan/article/details/7962508