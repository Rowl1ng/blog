
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>word2vec · GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    
    <link rel="stylesheet" href="gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-mermaid-gb3/mermaid/mermaid.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-anchor-navigation-ex/style/plugin.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-anchors/plugin.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-donate/plugin.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    


    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="alphago.html" />
    
    
    <link rel="prev" href="attention.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    
    
        
        <li>
            <a href="http://rowl1ng.com" target="_blank" class="custom-link">Home</a>
        </li>
    
    

    
    <li class="divider"></li>
    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="read-me.html">
            
                <a href="read-me.html">
            
                    
                    Read me
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">Programming</li>
        
        
    
        <li class="chapter " data-level="2.1" data-path="./">
            
                <a href="./">
            
                    
                    Python笔记本
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.1.1" data-path="basics.html">
            
                <a href="basics.html">
            
                    
                    基础
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.1.2" data-path="multiproccessing.html">
            
                <a href="multiproccessing.html">
            
                    
                    多线程
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.1.3" data-path="database.html">
            
                <a href="database.html">
            
                    
                    数据库
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.1.4" data-path="code.html">
            
                <a href="code.html">
            
                    
                    编码
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.1.5" data-path="debug.html">
            
                <a href="debug.html">
            
                    
                    调试
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.1.6" data-path="file.html">
            
                <a href="file.html">
            
                    
                    文件
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.1.7" data-path="log.html">
            
                <a href="log.html">
            
                    
                    日志
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.1.8" data-path="module.html">
            
                <a href="module.html">
            
                    
                    模块
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.1.9" data-path="OOP.html">
            
                <a href="OOP.html">
            
                    
                    面向对象编程
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.1.10" data-path="error.html">
            
                <a href="error.html">
            
                    
                    错误和异常
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.1.11" data-path="cython.html">
            
                <a href="cython.html">
            
                    
                    cython
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.1.12" data-path="superior.html">
            
                <a href="superior.html">
            
                    
                    高级特性
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.1.13" data-path="functional.html">
            
                <a href="functional.html">
            
                    
                    函数式编程
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2.2" data-path="engineering.html">
            
                <a href="engineering.html">
            
                    
                    工程化
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.3" data-path="linux.html">
            
                <a href="linux.html">
            
                    
                    linux
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.3.1" data-path="linux/trainandtest.html">
            
                <a href="linux/trainandtest.html">
            
                    
                    train&test
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2.4" data-path="latex.html">
            
                <a href="latex.html">
            
                    
                    Latex
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">Machine Learning</li>
        
        
    
        <li class="chapter " data-level="3.1" data-path="README 3.html">
            
                <a href="README 3.html">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.2" data-path="data_analyse.html">
            
                <a href="data_analyse.html">
            
                    
                    第-1章 数据分析
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.2.1" data-path="data_analysis/scikit-learn.html">
            
                <a href="data_analysis/scikit-learn.html">
            
                    
                    scikit-learn
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.2.2" data-path="data_analysis/pandas.html">
            
                <a href="data_analysis/pandas.html">
            
                    
                    pandas
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.2.3" data-path="data_analysis/jupyter.html">
            
                <a href="data_analysis/jupyter.html">
            
                    
                    Jupyter
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.2.4" data-path="data_analysis/numpy.html">
            
                <a href="data_analysis/numpy.html">
            
                    
                    numpy
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.2.4.1" data-path="data_analysis/numpy/array.html">
            
                <a href="data_analysis/numpy/array.html">
            
                    
                    array
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3.3" data-path="chapter1.html">
            
                <a href="chapter1.html">
            
                    
                    第0章 数学准备
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.3.1" data-path="inbox0.html">
            
                <a href="inbox0.html">
            
                    
                    待整理
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.3.2" data-path="function.html">
            
                <a href="function.html">
            
                    
                    函数
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.3.3" data-path="differential.html">
            
                <a href="differential.html">
            
                    
                    微分
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.3.4" data-path="integral.html">
            
                <a href="integral.html">
            
                    
                    积分
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.3.5" data-path="matrix.html">
            
                <a href="matrix.html">
            
                    
                    矩阵
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.3.6" data-path="probability.html">
            
                <a href="probability.html">
            
                    
                    概率
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.3.7" data-path="metrics.html">
            
                <a href="metrics.html">
            
                    
                    Metrics
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.3.8" data-path="distance.html">
            
                <a href="distance.html">
            
                    
                    距离
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.3.9" data-path="term.md.html">
            
                <a href="term.md.html">
            
                    
                    术语
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3.4" data-path="basic.html">
            
                <a href="basic.html">
            
                    
                    第1章 基础知识
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.4.1" data-path="generality.html">
            
                <a href="generality.html">
            
                    
                    方法概论
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.4.2" data-path="svm.html">
            
                <a href="svm.html">
            
                    
                    基础学习算法
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.4.3" data-path="crf.html">
            
                <a href="crf.html">
            
                    
                    条件随机场
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.4.4" data-path="normalization.html">
            
                <a href="normalization.html">
            
                    
                    normalization
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.4.5" data-path="regularization.html">
            
                <a href="regularization.html">
            
                    
                    regularization
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3.5" data-path="nnintro.html">
            
                <a href="nnintro.html">
            
                    
                    第2章 神经网络入门
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.5.1" data-path="nnfunction.html">
            
                <a href="nnfunction.html">
            
                    
                    函数
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.5.1.1" data-path="activation-function.html">
            
                <a href="activation-function.html">
            
                    
                    activation function
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.5.1.2" data-path="loss-function.html">
            
                <a href="loss-function.html">
            
                    
                    loss function
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3.5.2" data-path="nnstructure.html">
            
                <a href="nnstructure.html">
            
                    
                    神经网络结构
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.5.3" data-path="regulizer.html">
            
                <a href="regulizer.html">
            
                    
                    正则化网络
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.5.4" data-path="rnn.html">
            
                <a href="rnn.html">
            
                    
                    RNN
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.5.5" data-path="cnn.html">
            
                <a href="cnn.html">
            
                    
                    CNN
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.5.6" data-path="criterion.html">
            
                <a href="criterion.html">
            
                    
                    criterion
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.5.7" data-path="backbone.html">
            
                <a href="backbone.html">
            
                    
                    backbone
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.5.8" data-path="wen-ti.html">
            
                <a href="wen-ti.html">
            
                    
                    问题
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.5.8.1" data-path="problems/transfer-learning.html">
            
                <a href="problems/transfer-learning.html">
            
                    
                    transfer learning
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.5.8.2" data-path="problems/imbalance.html">
            
                <a href="problems/imbalance.html">
            
                    
                    样本不均衡
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.5.8.3" data-path="problems/few-shot-learning.html">
            
                <a href="problems/few-shot-learning.html">
            
                    
                    few-shot learning
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.5.8.4" data-path="wu-jian-du-xue-xi.html">
            
                <a href="wu-jian-du-xue-xi.html">
            
                    
                    无监督学习
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3.6" data-path="nnpractice.html">
            
                <a href="nnpractice.html">
            
                    
                    第3章 神经网络编程
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.6.1" data-path="keras.html">
            
                <a href="keras.html">
            
                    
                    keras
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.6.2" data-path="theano.html">
            
                <a href="theano.html">
            
                    
                    Theano
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.6.3" data-path="tensorflow.html">
            
                <a href="tensorflow.html">
            
                    
                    Tensorflow
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.6.4" data-path="caffe.html">
            
                <a href="caffe.html">
            
                    
                    caffe
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.6.5" data-path="layer.html">
            
                <a href="layer.html">
            
                    
                    layer
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.6.6" data-path="matlab.html">
            
                <a href="matlab.html">
            
                    
                    matlab
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.6.7" data-path="pytorch.html">
            
                <a href="pytorch.html">
            
                    
                    Pytorch
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.6.8" data-path="method.html">
            
                <a href="method.html">
            
                    
                    method
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3.7" data-path="deeplearning.html">
            
                <a href="deeplearning.html">
            
                    
                    第4章 深度学习探索
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.7.1" data-path="attention.html">
            
                <a href="attention.html">
            
                    
                    Attention
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="3.7.2" data-path="word2vec.html">
            
                <a href="word2vec.html">
            
                    
                    word2vec
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.7.3" data-path="alphago.html">
            
                <a href="alphago.html">
            
                    
                    AlphaGo
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.7.4" data-path="termsmd.html">
            
                <a href="termsmd.html">
            
                    
                    Terms
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.7.5" data-path="boost.html">
            
                <a href="boost.html">
            
                    
                    boost
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3.8" data-path="ying-yong.html">
            
                <a href="ying-yong.html">
            
                    
                    应用
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.8.1" data-path="application/audio.html">
            
                <a href="application/audio.html">
            
                    
                    语音
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.8.1.1" data-path="application/audio/ying-yong-yu-an-quan-ling-yu-de-yu-yin-ji-zhu.html">
            
                <a href="application/audio/ying-yong-yu-an-quan-ling-yu-de-yu-yin-ji-zhu.html">
            
                    
                    应用于安全领域的语音技术
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.8.1.2" data-path="application/audio/std.html">
            
                <a href="application/audio/std.html">
            
                    
                    内容无关
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.8.1.3" data-path="application/audio/yin-su.html">
            
                <a href="application/audio/yin-su.html">
            
                    
                    内容相关
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.8.1.4" data-path="application/audio/dai-zheng-li.md">
            
                <span>
            
                    
                    待整理
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3.8.2" data-path="application/an-quan.md">
            
                <span>
            
                    
                    安全
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.8.2.1" data-path="application/an-quan/e-yi-dai-ma-jian-ce.md">
            
                <span>
            
                    
                    恶意代码检测
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.8.2.2" data-path="application/an-quan/zi-dong-lou-dong-wa-jue.md">
            
                <span>
            
                    
                    脆弱性检测
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.8.2.3" data-path="application/an-quan/zi-dong-lou-dong-wa-jue.md">
            
                <span>
            
                    
                    自动漏洞挖掘
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    

    
        
        <li class="header">Computer Vision</li>
        
        
    
        <li class="chapter " data-level="4.1" data-path="README 2.html">
            
                <a href="README 2.html">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.2" data-path="chapter1.html">
            
                <a href="chapter1.html">
            
                    
                    第0章 数学准备
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="4.2.1" data-path="convolution.html">
            
                <a href="convolution.html">
            
                    
                    卷积
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="4.3" data-path="python_programming.html">
            
                <a href="python_programming.html">
            
                    
                    python编程
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="4.3.1" data-path="python_programming/opencv.html">
            
                <a href="python_programming/opencv.html">
            
                    
                    opencv
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.3.2" data-path="python_programming/matplotlib.html">
            
                <a href="python_programming/matplotlib.html">
            
                    
                    matplotlib
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.3.3" data-path="python_programming/skimage.html">
            
                <a href="python_programming/skimage.html">
            
                    
                    scikit-image
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.3.4" data-path="python_programming/visualize.html">
            
                <a href="python_programming/visualize.html">
            
                    
                    visualize
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.3.5" data-path="python_programming/froc.html">
            
                <a href="python_programming/froc.html">
            
                    
                    FROC
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.3.6" data-path="python_programming/patch.html">
            
                <a href="python_programming/patch.html">
            
                    
                    patch
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="4.4" data-path="ren-wu.html">
            
                <a href="ren-wu.html">
            
                    
                    任务
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="4.4.1" data-path="segmentation.html">
            
                <a href="segmentation.html">
            
                    
                    segmentation
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.4.2" >
            
                <span>
            
                    
                    detection
            
                </span>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="4.5" data-path="image_basics.html">
            
                <a href="image_basics.html">
            
                    
                    图像处理基础
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="4.5.1" data-path="ping-hua-hua.html">
            
                <a href="ping-hua-hua.html">
            
                    
                    平滑化
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.5.2" data-path="feature.html">
            
                <a href="feature.html">
            
                    
                    feature
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.5.3" data-path="tu-xiang-jun-heng-hua.md">
            
                <span>
            
                    
                    对比度
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.5.4" data-path="yu-zhi.html">
            
                <a href="yu-zhi.html">
            
                    
                    阈值
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="4.6" data-path="practice.html">
            
                <a href="practice.html">
            
                    
                    实践
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="4.6.1" data-path="lane.html">
            
                <a href="lane.html">
            
                    
                    车道线识别
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.6.2" data-path="roadnn.html">
            
                <a href="roadnn.html">
            
                    
                    RoadNN
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.6.3" data-path="mammogram.html">
            
                <a href="mammogram.html">
            
                    
                    mammogram
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.6.4" data-path="yi-liao-tu-xiang.html">
            
                <a href="yi-liao-tu-xiang.html">
            
                    
                    医疗图像
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    
        
        <li class="header">Math</li>
        
        
    
        <li class="chapter " data-level="5.1" data-path="probability.html">
            
                <a href="probability.html">
            
                    
                    Probability Theory
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="5.2" data-path="optimization.html">
            
                <a href="optimization.html">
            
                    
                    Nonliner Optimization
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="5.2.1" data-path="optimization/introduction.html">
            
                <a href="optimization/introduction.html">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="5.2.2" data-path="smo.html">
            
                <a href="smo.html">
            
                    
                    SMO
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="5.2.3" data-path="optimizer.html">
            
                <a href="optimizer.html">
            
                    
                    优化算法
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    
        
        <li class="header">Language</li>
        
        
    
        <li class="chapter " data-level="6.1" data-path="README 4.html">
            
                <a href="README 4.html">
            
                    
                    English
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="6.1.1" data-path="suffix.html">
            
                <a href="suffix.html">
            
                    
                    suffix
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="6.1.2" data-path="prefix.html">
            
                <a href="prefix.html">
            
                    
                    prefix
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="6.1.3" data-path="verb.html">
            
                <a href="verb.html">
            
                    
                    verb
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="6.1.4" data-path="synonym.html">
            
                <a href="synonym.html">
            
                    
                    synonym
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="6.1.5" data-path="math.html">
            
                <a href="math.html">
            
                    
                    math
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="6.1.6" data-path="material.html">
            
                <a href="material.html">
            
                    
                    material
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="6.1.7" data-path="others.html">
            
                <a href="others.html">
            
                    
                    others
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="6.2" data-path="ri-ben-yu.html">
            
                <a href="ri-ben-yu.html">
            
                    
                    日本語
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">画画</li>
        
        
    
        <li class="chapter " data-level="7.1" data-path="art/color.html">
            
                <a href="art/color.html">
            
                    
                    color
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="7.2" data-path="art/light.html">
            
                <a href="art/light.html">
            
                    
                    light
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">Music</li>
        
        
    
        <li class="chapter " data-level="8.1" data-path="music/gu-qin.html">
            
                <a href="music/gu-qin.html">
            
                    
                    古琴
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="." >word2vec</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <div id="anchor-navigation-ex-navbar"><i class="fa fa-anchor"></i><ul><li><a href="#word2vec">1. word2vec</a></li><ul><li><a href="#&#x5D4C;&#x5165;&#xFF08;embedding&#xFF09;">1.1. &#x5D4C;&#x5165;&#xFF08;Embedding&#xFF09;</a></li><li><a href="#word2vec">1.2. word2vec</a></li><li><a href="#abstract">1.3. Abstract</a></li><li><a href="#introduction">1.4. Introduction</a></li><li><a href="#models">1.5. Models</a></li><ul><li><a href="#1-nnlm">1.5.1. 1. NNLM</a></li><li><a href="#2-lbl">1.5.2. 2. LBL</a></li><li><a href="#glove">1.5.3. GloVe</a></li></ul><li><a href="#ID12">1.6. 2. Word Vector  </a></li><ul><li><a href="#13-nltk">1.6.1. 1.3 NLTK</a></li><li><a href="#12-&#x8BFB;&#x53D6;&#x6570;&#x636E;">1.6.2. 1.2 &#x8BFB;&#x53D6;&#x6570;&#x636E;</a></li><li><a href="#21-construct-matrix">1.6.3. 2.1 Construct Matrix</a></li><li><a href="#211-build-vocabulary">1.6.4. 2.1.1 Build Vocabulary</a></li><li><a href="#22-&#x8BAD;&#x7EC3;-word-vector-">1.6.5. 2.2 &#x8BAD;&#x7EC3; word vector :</a></li><li><a href="#&#x91C7;&#x96C6;&#x6570;&#x636E;">1.6.6. &#x91C7;&#x96C6;&#x6570;&#x636E;</a></li><li><a href="#22-gensimmodelword2vec">1.6.7. 2.2 gensim.model.Word2Vec</a></li></ul><li><a href="#multi-label">1.7. Multi-Label</a></li><ul><li><a href="#binary-relevance-br">1.7.1. Binary Relevance (BR)</a></li></ul><li><a href="#&#x5DE5;&#x5177;&#x7C7B;">1.8. &#x5DE5;&#x5177;&#x7C7B;</a></li><ul><li><a href="#1documentpy">1.8.1. 1.Document.py</a></li></ul></ul></ul></div><a href="#word2vec" id="anchorNavigationExGoTop"><i class="fa fa-arrow-up"></i></a><h1 id="word2vec"><a name="word2vec" class="plugin-anchor" href="#word2vec"><i class="fa fa-link" aria-hidden="true"></i></a><a name="word2vec" class="anchor-navigation-ex-anchor" href="#word2vec"><i class="fa fa-link" aria-hidden="true"></i></a>1. word2vec</h1>
<p>NNLM&#x7B2C;&#x4E94;&#x5468;&#x7684;&#x7F16;&#x7A0B;&#x4F5C;&#x4E1A;&#x662F;&#x7528;Matlab&#x5199;&#x7F51;&#x7EDC;&#x9884;&#x6D4B;&#x4E0B;&#x4E00;&#x4E2A;&#x8BCD;&#xFF0C;&#x8F93;&#x51FA;&#x8BCD;&#x5411;&#x91CF;&#x8BED;&#x8A00;&#x6A21;&#x578B;&#x3002;&#x4E4B;&#x524D;&#x867D;&#x7136;&#x770B;&#x8FC7;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x8BED;&#x8A00;&#x6A21;&#x578B;&#x7684;&#x8BBA;&#x6587;&#xFF0C;&#x4E5F;&#x7528;&#x8BCD;&#x5411;&#x91CF;&#x6A21;&#x578B;&#x8DD1;&#x8FC7;NLP&#x4EFB;&#x52A1;&#xFF0C;&#x4F46;&#x4ECE;&#x6765;&#x6CA1;&#x6709;&#x81EA;&#x5DF1;&#x52A8;&#x624B;&#x5B9E;&#x73B0;&#x8FC7;&#xFF0C;&#x4E5F;&#x5C31;&#x66F4;&#x4E0D;&#x53EF;&#x80FD;&#x601D;&#x8003;&#x4E00;&#x4E9B;&#x5B9E;&#x73B0;&#x4E0A;&#x7684;&#x7EC6;&#x8282;&#x8BA1;&#x7B97;&#x95EE;&#x9898;&#x3002;</p>
<p>&#x8FD9;&#x6B21;&#x7F16;&#x7A0B;&#x4F5C;&#x4E1A;&#x63D0;&#x4F9B;&#x597D;&#x4E86;&#x5927;&#x90E8;&#x5206;&#x7684;&#x5173;&#x952E;&#x6A21;&#x5757;&#xFF0C;&#x4EE5;ABCD&#x9009;&#x62E9;&#x7684;&#x5F62;&#x5F0F;&#x8BA9;&#x5B66;&#x751F;&#x81EA;&#x5DF1;&#x9009;&#x51FA;&#x6B63;&#x786E;&#x7684;&#x5B9E;&#x73B0;&#x8BED;&#x53E5;&#xFF0C;&#x53EF;&#x4EE5;&#x8BF4;&#x5728;&#x5F88;&#x5927;&#x7A0B;&#x5EA6;&#x4E0A;&#x7B80;&#x5316;&#x4E86;&#x5B9E;&#x73B0;&#x8FC7;&#x7A0B;&#xFF0C;&#x4E5F;&#x6253;&#x6D88;&#x4E86;&#x754F;&#x96BE;&#x5FC3;&#x7406;&#x3002;</p>
<p>&#x9996;&#x5148;&#x6765;&#x7406;&#x89E3;&#x5D4C;&#x5165;&#x7684;&#x6982;&#x5FF5;&#xFF1A;</p>
<h2 id="&#x5D4C;&#x5165;&#xFF08;embedding&#xFF09;"><a name="&#x5D4C;&#x5165;&#xFF08;embedding&#xFF09;" class="plugin-anchor" href="#&#x5D4C;&#x5165;&#xFF08;embedding&#xFF09;"><i class="fa fa-link" aria-hidden="true"></i></a><a name="&#x5D4C;&#x5165;&#xFF08;embedding&#xFF09;" class="anchor-navigation-ex-anchor" href="#&#x5D4C;&#x5165;&#xFF08;embedding&#xFF09;"><i class="fa fa-link" aria-hidden="true"></i></a>1.1. &#x5D4C;&#x5165;&#xFF08;Embedding&#xFF09;</h2>
<p>&#x4E00;&#x4E2A;&#x5D4C;&#x5165;&#x6620;&#x5C04;&#x5230;&#x4E00;&#x4E2A;&#x8F93;&#x5165;&#x8868;&#x5F81;&#xFF0C;&#x6BD4;&#x5982;&#x4E00;&#x4E2A;&#x8BCD;&#x6216;&#x4E00;&#x53E5;&#x8BDD;&#x6620;&#x5C04;&#x5230;&#x4E00;&#x4E2A;&#x77E2;&#x91CF;&#x3002;&#x4E00;&#x79CD;&#x6D41;&#x884C;&#x7684;&#x5D4C;&#x5165;&#x662F;&#x8BCD;&#x8BED;&#x5D4C;&#x5165;&#xFF08;word embedding&#xFF0C;&#x56FD;&#x5185;&#x5E38;&#x7528;&#x7684;&#x8BF4;&#x6CD5;&#x662F;&#xFF1A;&#x8BCD;&#x5411;&#x91CF;&#xFF09;&#xFF0C;&#x5982; word2vec &#x6216; GloVe&#x3002;&#x6211;&#x4EEC;&#x4E5F;&#x53EF;&#x4EE5;&#x5D4C;&#x5165;&#x53E5;&#x5B50;&#x3001;&#x6BB5;&#x843D;&#x6216;&#x56FE;&#x50CF;&#x3002;&#x6BD4;&#x5982;&#x8BF4;&#xFF0C;&#x901A;&#x8FC7;&#x5C06;&#x56FE;&#x50CF;&#x548C;&#x4ED6;&#x4EEC;&#x7684;&#x6587;&#x672C;&#x63CF;&#x8FF0;&#x6620;&#x5C04;&#x5230;&#x4E00;&#x4E2A;&#x5171;&#x540C;&#x7684;&#x5D4C;&#x5165;&#x7A7A;&#x95F4;&#x4E2D;&#x5E76;&#x6700;&#x5C0F;&#x5316;&#x5B83;&#x4EEC;&#x4E4B;&#x95F4;&#x7684;&#x8DDD;&#x79BB;&#xFF0C;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x5C06;&#x6807;&#x7B7E;&#x548C;&#x56FE;&#x50CF;&#x8FDB;&#x884C;&#x5339;&#x914D;&#x3002;&#x5D4C;&#x5165;&#x53EF;&#x4EE5;&#x88AB;&#x660E;&#x786E;&#x5730;&#x5B66;&#x4E60;&#x5230;&#xFF0C;&#x6BD4;&#x5982;&#x5728; word2vec &#x4E2D;&#xFF1B;&#x5D4C;&#x5165;&#x4E5F;&#x53EF;&#x4F5C;&#x4E3A;&#x76D1;&#x7763;&#x4EFB;&#x52A1;&#x7684;&#x4E00;&#x90E8;&#x5206;&#x4F8B;&#x5982;&#x60C5;&#x611F;&#x5206;&#x6790;&#xFF08;Sentiment Analysis&#xFF09;&#x3002;&#x901A;&#x5E38;&#x4E00;&#x4E2A;&#x7F51;&#x7EDC;&#x7684;&#x8F93;&#x5165;&#x5C42;&#x662F;&#x901A;&#x8FC7;&#x9884;&#x5148;&#x8BAD;&#x7EC3;&#x7684;&#x5D4C;&#x5165;&#x8FDB;&#x884C;&#x521D;&#x59CB;&#x5316;&#xFF0C;&#x7136;&#x540E;&#x518D;&#x6839;&#x636E;&#x5F53;&#x524D;&#x4EFB;&#x52A1;&#x8FDB;&#x884C;&#x5FAE;&#x8C03;&#xFF08;fine-tuned&#xFF09;&#x3002;</p>
<h2 id="word2vec"><a name="word2vec" class="plugin-anchor" href="#word2vec"><i class="fa fa-link" aria-hidden="true"></i></a><a name="word2vec" class="anchor-navigation-ex-anchor" href="#word2vec"><i class="fa fa-link" aria-hidden="true"></i></a>1.2. word2vec</h2>
<p>word2vec &#x662F;&#x4E00;&#x79CD;&#x8BD5;&#x56FE;&#x901A;&#x8FC7;&#x9884;&#x6D4B;&#x6587;&#x6863;&#x4E2D;&#x8BDD;&#x8BED;&#x7684;&#x4E0A;&#x4E0B;&#x6587;&#x6765;&#x5B66;&#x4E60;&#x8BCD;&#x5411;&#x91CF;&#xFF08;word embedding&#xFF09;&#x7684;&#x7B97;&#x6CD5;&#x548C;&#x5DE5;&#x5177; (<a href="https://code.google.com/p/word2vec/)&#x3002;&#x6700;&#x7EC8;&#x5F97;&#x5230;&#x7684;&#x8BCD;&#x77E2;&#x91CF;&#xFF08;word" target="_blank">https://code.google.com/p/word2vec/)&#x3002;&#x6700;&#x7EC8;&#x5F97;&#x5230;&#x7684;&#x8BCD;&#x77E2;&#x91CF;&#xFF08;word</a> vector&#xFF09;&#x6709;&#x4E00;&#x4E9B;&#x6709;&#x8DA3;&#x7684;&#x6027;&#x8D28;&#xFF0C;&#x4F8B;&#x5982;vector(&apos;queen&apos;) ~= vector(&apos;king&apos;) - vector(&apos;man&apos;) + vector(&apos;woman&apos;) &#xFF08;&#x5973;&#x738B;~=&#x56FD;&#x738B;-&#x7537;&#x4EBA;+&#x5973;&#x4EBA;&#xFF09;&#x3002;&#x4E24;&#x4E2A;&#x4E0D;&#x540C;&#x7684;&#x76EE;&#x6807;&#x51FD;&#x6570;&#x53EF;&#x4EE5;&#x7528;&#x6765;&#x5B66;&#x4E60;&#x8FD9;&#x4E9B;&#x5D4C;&#x5165;&#xFF1A;Skip-Gram &#x76EE;&#x6807;&#x51FD;&#x6570;&#x5C1D;&#x8BD5;&#x9884;&#x6D4B;&#x4E00;&#x4E2A;&#x8BCD;&#x7684;&#x4E0A;&#x4E0B;&#x6587;&#xFF0C;CBOW  &#x76EE;&#x6807;&#x51FD;&#x6570;&#x5219;&#x5C1D;&#x8BD5;&#x4ECE;&#x8BCD;&#x4E0A;&#x4E0B;&#x6587;&#x9884;&#x6D4B;&#x8FD9;&#x4E2A;&#x8BCD;&#x3002;</p>
<p>&#x8BBA;&#x6587;&#xFF1A;&#x5411;&#x91CF;&#x7A7A;&#x95F4;&#x4E2D;&#x8BCD;&#x6C47;&#x8868;&#x5F81;&#x7684;&#x6709;&#x6548;&#x8BC4;&#x4F30;&#xFF08;Efficient Estimation of Word Representations in Vector Space&#xFF09;
&#x8BBA;&#x6587;&#xFF1A;&#x5206;&#x5E03;&#x5F0F;&#x8BCD;&#x6C47;&#x548C;&#x77ED;&#x8BED;&#x8868;&#x5F81;&#x4EE5;&#x53CA;&#x4ED6;&#x4EEC;&#x7684;&#x7EC4;&#x5408;&#x6027;&#xFF08;Distributed Representations of Words and Phrases and their Compositionality&#xFF09;
&#x8BBA;&#x6587;&#xFF1A;&#x89E3;&#x91CA; word2vec &#x53C2;&#x6570;&#x5B66;&#x4E60;&#xFF08;word2vec Parameter Learning Explained&#xFF09;</p>
<h2 id="abstract"><a name="abstract" class="plugin-anchor" href="#abstract"><i class="fa fa-link" aria-hidden="true"></i></a><a name="abstract" class="anchor-navigation-ex-anchor" href="#abstract"><i class="fa fa-link" aria-hidden="true"></i></a>1.3. Abstract</h2>
<p>Word2vec training is an unsupervised task, there&#x2019;s no good way to objectively evaluate the result. Evaluation depends on your end application.</p>
<h2 id="introduction"><a name="introduction" class="plugin-anchor" href="#introduction"><i class="fa fa-link" aria-hidden="true"></i></a><a name="introduction" class="anchor-navigation-ex-anchor" href="#introduction"><i class="fa fa-link" aria-hidden="true"></i></a>1.4. Introduction</h2>
<p>The success of machine learning methods in NLP tasks depends much on word representation, since different representations may encode different explanatory factors of variation behind the word. With the rapid development of deep learning techniques,researchers have started to train complex and deep models on large amounts of text corpus, to learn distributed representations of words(also known as word embeddings) in the form of continuous vectors.
While conventional NLP techniques usually represent words as indices in a vocabulary causing no notion of relationship between words, word embeddings learned by deep learing approaches aim at explicitly encoding many semantic relationships as well as linguistic regularities and patterns into the new word embedding space.
 &#x4E0D;&#x540C;&#x4E8E;&#x4F20;&#x7EDF;one-hot&#xFF0C;distributed&#x8BCD;&#x5411;&#x91CF;&#x5305;&#x542B;&#x4E86;&#x8BCD;&#x4E0E;&#x8BCD;&#x4E4B;&#x95F4;&#x7684;&#x5173;&#x8054;
In this paper, we introduce a benchmark collection\cite{how}, which is built from several different data source, to measure quality of word embeddings from different aspects.
&#x590D;&#x73B0;&#x4E86;&#x82E5;&#x5E72;&#x4E2A;task&#xFF0C;&#x6765;&#x8861;&#x91CF;&#x8BCD;&#x5411;&#x91CF;&#x7684;&#x4F18;&#x52A3;&#x3002;</p>
<h2 id="models"><a name="models" class="plugin-anchor" href="#models"><i class="fa fa-link" aria-hidden="true"></i></a><a name="models" class="anchor-navigation-ex-anchor" href="#models"><i class="fa fa-link" aria-hidden="true"></i></a>1.5. Models</h2>
<h3 id="1-nnlm"><a name="1-nnlm" class="plugin-anchor" href="#1-nnlm"><i class="fa fa-link" aria-hidden="true"></i></a><a name="1-nnlm" class="anchor-navigation-ex-anchor" href="#1-nnlm"><i class="fa fa-link" aria-hidden="true"></i></a>1.5.1. 1. NNLM</h3>
<p>&#x8FD9;&#x91CC;&#x770B;&#x7684;&#x662F;Bengio&#x7684;<a href="http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf" target="_blank">&#x8BBA;&#x6587;</a>
Bengio et al. \cite{nnlm} first proposed a Neural Network Language Model (NNLM) that simultaneously learns a word embedding and a language model.The language model utilizes several previous words to predict the distribution of the next word.For each sample in the corpus ,we maximize the log-likelihood of the probability of the last word given the previous words.This model uses a concatenation of the previous words&apos; embeddings as the input.The model structure is a feed-forward neural network with one hidden layer.</p>
<h3 id="2-lbl"><a name="2-lbl" class="plugin-anchor" href="#2-lbl"><i class="fa fa-link" aria-hidden="true"></i></a><a name="2-lbl" class="anchor-navigation-ex-anchor" href="#2-lbl"><i class="fa fa-link" aria-hidden="true"></i></a>1.5.2. 2. LBL</h3>
<p>The Log-Bilinear Language Model(LBL) proposed by Mnih and Hinton combines Bengio&apos;s Hierachical NNLM and Log Bi-Linear.It uses a log-bilinear energy function that is almost equal to that of the NNLM and removes the non-linear activation function tanh. </p>
<p>A previous study \cite{lbl} proposed a widely used model architecture for estimating neural network language model.</p>
<h3 id="glove"><a name="glove" class="plugin-anchor" href="#glove"><i class="fa fa-link" aria-hidden="true"></i></a><a name="glove" class="anchor-navigation-ex-anchor" href="#glove"><i class="fa fa-link" aria-hidden="true"></i></a>1.5.3. GloVe</h3>
<p>Glove &#x662F;&#x4E00;&#x79CD;&#x4E3A;&#x8BDD;&#x8BED;&#x83B7;&#x53D6;&#x77E2;&#x91CF;&#x8868;&#x5F81;&#xFF08;&#x5D4C;&#x5165;&#xFF09;&#x7684;&#x65E0;&#x76D1;&#x7763;&#x5B66;&#x4E60;&#x7B97;&#x6CD5;&#x3002;GloVe &#x7684;&#x4F7F;&#x7528;&#x76EE;&#x7684;&#x548C; word2vec &#x4E00;&#x6837;&#xFF0C;&#x4F46; GloVe &#x5177;&#x6709;&#x4E0D;&#x540C;&#x7684;&#x77E2;&#x91CF;&#x8868;&#x5F81;&#xFF0C;&#x56E0;&#x4E3A;&#x5B83;&#x662F;&#x5728;&#x5171;&#x73B0;&#xFF08;co-occurrence&#xFF09;&#x7EDF;&#x8BA1;&#x6570;&#x636E;&#x4E0A;&#x8BAD;&#x7EC3;&#x7684;&#x3002;</p>
<p>&#x8BBA;&#x6587;&#xFF1A;GloVe&#xFF1A;&#x7528;&#x4E8E;&#x8BCD;&#x6C47;&#x8868;&#x5F81;&#xFF08;Word Representation&#xFF09;&#x7684;&#x5168;&#x5C40;&#x77E2;&#x91CF;&#xFF08;Global Vector&#xFF09;&#xFF08;GloVe: Global Vectors for Word Representation &#xFF09;</p>
<h2 id="ID12"><a name="ID12" class="plugin-anchor" href="#ID12"><i class="fa fa-link" aria-hidden="true"></i></a><a name="ID12" class="anchor-navigation-ex-anchor" href="#ID12"><i class="fa fa-link" aria-hidden="true"></i></a>1.6. 2. Word Vector  </h2>
<p>&#x5728;&#x8BAD;&#x7EC3;&#x6A21;&#x578B;&#x524D;&#xFF0C;&#x5BF9;&#x8BED;&#x6599;&#x6784;&#x5EFA;&#x5408;&#x9002;&#x7684;&#x8BCD;&#x5411;&#x91CF;&#x6A21;&#x578B;&#x3002;
&#x4F7F;&#x7528;&#x8BC4;&#x8BBA;&#x8BAD;&#x7EC3;&#x8BCD;&#x5411;&#x91CF;&#x6A21;&#x578B; &#x7406;&#x8BBA;&#x4E0A;&#xFF0C;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;&#x4E0D;&#x540C;&#x7684;&#x8BED;&#x6599;&#x8FDB;&#x884C;&#x8BAD;&#x7EC3;&#x6216;&#x8005;&#x76F4;&#x63A5;&#x4F7F;&#x7528;&#x5DF2;&#x7ECF;&#x8BAD;&#x7EC3;&#x597D;&#x7684;&#x3002;</p>
<h3 id="13-nltk"><a name="13-nltk" class="plugin-anchor" href="#13-nltk"><i class="fa fa-link" aria-hidden="true"></i></a><a name="13-nltk" class="anchor-navigation-ex-anchor" href="#13-nltk"><i class="fa fa-link" aria-hidden="true"></i></a>1.6.1. 1.3 NLTK</h3>
<h4 id="1&#x3001;-sentences-segment&#xFF08;&#x5206;&#x53E5;&#xFF09;"><a name="1&#x3001;-sentences-segment&#xFF08;&#x5206;&#x53E5;&#xFF09;" class="plugin-anchor" href="#1&#x3001;-sentences-segment&#xFF08;&#x5206;&#x53E5;&#xFF09;"><i class="fa fa-link" aria-hidden="true"></i></a><a name="1&#x3001;-sentences-segment&#xFF08;&#x5206;&#x53E5;&#xFF09;" class="anchor-navigation-ex-anchor" href="#1&#x3001;-sentences-segment&#xFF08;&#x5206;&#x53E5;&#xFF09;"><i class="fa fa-link" aria-hidden="true"></i></a>1&#x3001; Sentences Segment&#xFF08;&#x5206;&#x53E5;&#xFF09;</h4>
<p>&#x53EF;&#x4EE5;&#x4F7F;&#x7528;NLTK&#x4E2D;&#x7684; punkt sentence segmenter&#x3002;</p>
<pre><code class="lang-python">nltk.set_proxy(<span class="hljs-string">&quot;**.com:80&quot;</span>) //&#x8BBE;&#x7F6E;&#x4EE3;&#x7406;
nltk.download(<span class="hljs-string">&apos;punkt&apos;</span>)
</code></pre>
<h3 id="12-&#x8BFB;&#x53D6;&#x6570;&#x636E;"><a name="12-&#x8BFB;&#x53D6;&#x6570;&#x636E;" class="plugin-anchor" href="#12-&#x8BFB;&#x53D6;&#x6570;&#x636E;"><i class="fa fa-link" aria-hidden="true"></i></a><a name="12-&#x8BFB;&#x53D6;&#x6570;&#x636E;" class="anchor-navigation-ex-anchor" href="#12-&#x8BFB;&#x53D6;&#x6570;&#x636E;"><i class="fa fa-link" aria-hidden="true"></i></a>1.6.2. 1.2 &#x8BFB;&#x53D6;&#x6570;&#x636E;</h3>
<pre><code class="lang-python">        train = []
        self.cur.execute(<span class="hljs-string">&quot;SELECT * FROM Bug_Report_Data&quot;</span>)
        <span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> self.cur:
            review = str(row[<span class="hljs-number">16</span>])
            review= str(review.decode(<span class="hljs-string">&apos;utf-8&apos;</span>, errors=<span class="hljs-string">&apos;ignore&apos;</span>))
            train.append((review, <span class="hljs-string">&apos;bug&apos;</span>))
</code></pre>
<h4 id="training"><a name="training" class="plugin-anchor" href="#training"><i class="fa fa-link" aria-hidden="true"></i></a><a name="training" class="anchor-navigation-ex-anchor" href="#training"><i class="fa fa-link" aria-hidden="true"></i></a>Training</h4>
<h5 id="param"><a name="param" class="plugin-anchor" href="#param"><i class="fa fa-link" aria-hidden="true"></i></a><a name="param" class="anchor-navigation-ex-anchor" href="#param"><i class="fa fa-link" aria-hidden="true"></i></a>Param</h5>
<ul>
<li><code>sg</code> defines the <strong>training algorithm</strong>. By default (<code>sg=0</code>), CBOW is used. Otherwise (<code>sg=1</code>), skip-gram is employed.</li>
<li><code>size</code> 
= the dimensionality of the feature vectors.
the size of the NN layers, which correspond to the &#x201C;degrees&#x201D; of freedom the training algorithm has.Bigger size values require more training data, but can lead to better (more accurate) models. Reasonable values are in the tens to hundreds.</li>
<li><code>window</code> is the maximum distance between the current and predicted word within a sentence.</li>
<li><code>alpha</code> is the initial learning rate (will linearly drop to zero as training progresses).</li>
<li><code>seed</code> = for the random number generator. Initial vectors for each word are seeded with a hash of the concatenation of word + str(seed).</li>
<li><code>min_count</code> 
= ignore all words with total frequency lower than this.
It is for pruning the internal dictionary. Words that appear only once or twice in a billion-word corpus are probably uninteresting typos and garbage. In addition, there&#x2019;s not enough data to make any meaningful training on those words, so it&#x2019;s best to ignore them.</li>
<li><code>max_vocab_size</code> = limit RAM during vocabulary building; if there are more unique words than this, then prune the infrequent ones. Every 10 million word types need about 1GB of RAM. Set to <code>None</code> for no limit (default).</li>
<li><code>sample</code> = threshold for configuring which higher-frequency words are randomly downsampled; default is 1e-3, useful range is (0, 1e-5).</li>
<li><code>workers</code> 
= use this many worker threads to train the model (=faster training with multicore machines).for training parallelization, to speed up training.
The workers parameter has only effect if you have <strong>Cython</strong> installed. Without Cython, you&#x2019;ll only be able to use one core because of the GIL (and word2vec training will be miserably slow).</li>
<li><code>hs</code> = if 1, hierarchical softmax will be used for model training. If set to 0 (default), and <code>negative</code> is non-zero, negative sampling will be used.</li>
<li><code>negative</code> = if &gt; 0, negative sampling will be used, the int for negative specifies how many &quot;noise words&quot; should be drawn (usually between 5-20). Default is 5. If set to 0, no negative samping is used.</li>
<li><code>cbow_mean</code> = if 0, use the sum of the context word vectors. If 1 (default), use the mean. Only applies when cbow is used.</li>
<li><code>hashfxn</code> = hash function to use to randomly <strong>initialize</strong> weights, for increased training reproducibility. Default is Python&apos;s rudimentary built in hash function.</li>
<li><code>iter</code> = number of iterations (epochs) over the corpus.</li>
<li><code>trim_rule</code> = vocabulary trimming rule, specifies whether certain words should remain in the vocabulary, be trimmed away, or handled using the default (discard if word count &lt; min_count). Can be None (min_count will be used), or a callable that accepts parameters (word, count, min_count) and returns either <code>util.RULE_DISCARD</code>, <code>util.RULE_KEEP</code> or <code>util.RULE_DEFAULT</code>. Note: The rule, if given, is only used prune vocabulary during <code>build_vocab()</code> and is not stored as part of the model.</li>
<li><code>sorted_vocab</code> = if 1 (default), sort the vocabulary by descending frequency before  assigning word indexes.</li>
<li><code>batch_words</code> = target size (in words) for batches of examples passed to worker threads (and thus cython routines). Default is 10000. (Larger batches can be passed if individual texts are longer, but the cython code may truncate.)</li>
</ul>
<h3 id="21-construct-matrix"><a name="21-construct-matrix" class="plugin-anchor" href="#21-construct-matrix"><i class="fa fa-link" aria-hidden="true"></i></a><a name="21-construct-matrix" class="anchor-navigation-ex-anchor" href="#21-construct-matrix"><i class="fa fa-link" aria-hidden="true"></i></a>1.6.3. 2.1 Construct Matrix</h3>
<p>zero-pad or shortan &#x6587;&#x672C;&#x81F3;&#x56FA;&#x5B9A;&#x5927;&#x5C0F; $n$.
&#x4ECE;<code>sentences</code>&#x8FED;&#x4EE3;&#x5668;&#x521D;&#x59CB;&#x5316;&#x6A21;&#x578B;. Each sentence is a list of words (unicode strings) that will be used for training.
The <code>sentences</code> iterable can be simply a list, but for larger corpora,consider an iterable that streams the sentences directly from disk/network.
See :class:<code>BrownCorpus</code>, :class:<code>Text8Corpus</code> or :class:<code>LineSentence</code> in this module for such examples.
If you don&apos;t supply <code>sentences</code>, the model is left uninitialized -- use if you plan to initialize it in some other way.</p>
<h3 id="211-build-vocabulary"><a name="211-build-vocabulary" class="plugin-anchor" href="#211-build-vocabulary"><i class="fa fa-link" aria-hidden="true"></i></a><a name="211-build-vocabulary" class="anchor-navigation-ex-anchor" href="#211-build-vocabulary"><i class="fa fa-link" aria-hidden="true"></i></a>1.6.4. 2.1.1 Build Vocabulary</h3>
<p>Build vocabulary from a sequence of sentences (can be a once-only generator stream). Each sentence must be a list of <strong>unicode</strong> strings.</p>
<pre><code class="lang-python">self.scan_vocab(sentences, trim_rule=trim_rule)  <span class="hljs-comment"># initial survey</span>
self.scale_vocab(keep_raw_vocab=keep_raw_vocab, trim_rule=trim_rule)  <span class="hljs-comment"># trim by min_count &amp; precalculate downsampling</span>
self.finalize_vocab()  <span class="hljs-comment"># build tables &amp; arrays</span>
</code></pre>
<p>Create a binary <strong>Huffman tree</strong> using stored vocabulary word counts. Frequent words will have shorter binary codes. Called internally from <code>build_vocab()</code></p>
<p> Get all the word2vec vectors in a 2D matrix and fit the scaler on it. This scaler can be used afterwards for normalizing feature matrices.</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fit_scaler</span><span class="hljs-params">(data_dir, word2vec_model=WORD2VEC_MODELPATH, batch_size=<span class="hljs-number">1024</span>, persist_to_path=None)</span>:</span>
</code></pre>
<h4 id="212-&#x521D;&#x59CB;&#x5316;matrix"><a name="212-&#x521D;&#x59CB;&#x5316;matrix" class="plugin-anchor" href="#212-&#x521D;&#x59CB;&#x5316;matrix"><i class="fa fa-link" aria-hidden="true"></i></a><a name="212-&#x521D;&#x59CB;&#x5316;matrix" class="anchor-navigation-ex-anchor" href="#212-&#x521D;&#x59CB;&#x5316;matrix"><i class="fa fa-link" aria-hidden="true"></i></a>2.1.2 &#x521D;&#x59CB;&#x5316;matrix</h4>
<pre><code class="lang-python">self.vocab = {}  <span class="hljs-comment"># mapping from a word (string) to a Vocab object</span>
self.index2word = []  <span class="hljs-comment"># map from a word&apos;s matrix index (int) to word (string)</span>
</code></pre>
<p>&#x9009;&#x53D6;&#x4E00;&#x4E2A;seed string&#xFF0C;&#x5BF9;vocabulary&#x4E2D;&#x7684;word&#x9010;&#x4E2A;&#x521D;&#x59CB;&#x5316;random vector&#x3002;</p>
<pre><code class="lang-python">once = random.RandomState(self.hashfxn(seed_string) &amp; <span class="hljs-number">0xffffffff</span>)
<span class="hljs-keyword">return</span> (once.rand(self.vector_size) - <span class="hljs-number">0.5</span>) / self.vector_size
</code></pre>
<h3 id="22-&#x8BAD;&#x7EC3;-word-vector-"><a name="22-&#x8BAD;&#x7EC3;-word-vector-" class="plugin-anchor" href="#22-&#x8BAD;&#x7EC3;-word-vector-"><i class="fa fa-link" aria-hidden="true"></i></a><a name="22-&#x8BAD;&#x7EC3;-word-vector-" class="anchor-navigation-ex-anchor" href="#22-&#x8BAD;&#x7EC3;-word-vector-"><i class="fa fa-link" aria-hidden="true"></i></a>1.6.5. 2.2 &#x8BAD;&#x7EC3; word vector :</h3>
<pre><code>    &gt;&gt;&gt; from magpie import MagpieModel
    &gt;&gt;&gt; model = MagpieModel()
    &gt;&gt;&gt; model.train_word2vec(&apos;/path/to/training-directory&apos;, vec_dim=100)
</code></pre><h3 id="&#x91C7;&#x96C6;&#x6570;&#x636E;"><a name="&#x91C7;&#x96C6;&#x6570;&#x636E;" class="plugin-anchor" href="#&#x91C7;&#x96C6;&#x6570;&#x636E;"><i class="fa fa-link" aria-hidden="true"></i></a><a name="&#x91C7;&#x96C6;&#x6570;&#x636E;" class="anchor-navigation-ex-anchor" href="#&#x91C7;&#x96C6;&#x6570;&#x636E;"><i class="fa fa-link" aria-hidden="true"></i></a>1.6.6. &#x91C7;&#x96C6;&#x6570;&#x636E;</h3>
<h3 id="22-gensimmodelword2vec"><a name="22-gensimmodelword2vec" class="plugin-anchor" href="#22-gensimmodelword2vec"><i class="fa fa-link" aria-hidden="true"></i></a><a name="22-gensimmodelword2vec" class="anchor-navigation-ex-anchor" href="#22-gensimmodelword2vec"><i class="fa fa-link" aria-hidden="true"></i></a>1.6.7. 2.2 gensim.model.Word2Vec</h3>
<pre><code class="lang-python"><span class="hljs-meta">&gt;&gt;&gt; </span>model = Word2Vec(sentences, size=<span class="hljs-number">100</span>, window=<span class="hljs-number">5</span>, min_count=<span class="hljs-number">5</span>, workers=<span class="hljs-number">4</span>)
</code></pre>
<p><script type="math/tex; ">\not 0</script>
&#x4E0D;&#x7EE7;&#x7EED;&#x8BAD;&#x7EC3;&#x7684;&#x8BDD;&#xFF0C;&#x8C03;&#x7528;</p>
<pre><code class="lang-python">model.init_sims(replace=<span class="hljs-keyword">True</span>)
</code></pre>
<p>L2 normalize&#xFF1A;
$
y<em>i=\frac{x_i}{\sum</em>{i=1}^n{x_1}^2}
$</p>
<p>cpu_count=8</p>
<pre><code>$ python train_word2vec_model.py wiki.en.txt wiki.en.text.model wiki.en.text.vector
</code></pre><p> calling Word2Vec(sentences) will run two passes over the sentences iterator. </p>
<ul>
<li>The first pass collects words and their frequencies to build an internal dictionary tree structure.</li>
<li>The second pass trains the neural model.<pre><code>2016-05-08 22:11:43,575: INFO: running train_word2vec_model.py wiki.en.txt wiki.en.text.model wiki.en.text.vector
2016-05-08 22:11:43,575: INFO: collecting all words and their counts
2016-05-08 22:11:43,599: INFO: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2016-05-08 22:11:52,334: INFO: PROGRESS: at sentence #10000, processed 29237917 words, keeping 426680 word types
...
2016-05-08 22:25:14,292: INFO: PROGRESS: at sentence #4050000, processed 2197557235 words, keeping 8508124 word types
2016-05-08 22:25:14,760: INFO: collected 8511566 word types from a corpus of 2198527566 raw words and 4053349 sentences
2016-05-08 22:25:32,895: INFO: min_count=5 retains 2082765 unique words (drops 6428801)
2016-05-08 22:25:32,895: INFO: min_count leaves 2188708620 word corpus (99% of original 2198527566)
2016-05-08 22:25:44,397: INFO: deleting the raw counts dictionary of 8511566 items
2016-05-08 22:25:45,418: INFO: sample=0.001 downsamples 23 most-common words
2016-05-08 22:25:45,419: INFO: downsampling leaves estimated 1781672804 word corpus (81.4% of prior 2188708620)
2016-05-08 22:25:45,419: INFO: estimated required memory for 2082765 words and 100 dimensions: 2707594500 bytes
2016-05-08 22:25:52,354: INFO: resetting layer weights
2016-05-08 22:26:25,949: INFO: training model with 8 workers on 2082765 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5
2016-05-08 22:26:25,949: INFO: expecting 4053349 sentences, matching count from corpus used for vocabulary survey
...
2016-05-09 02:44:26,985: INFO: worker thread finished; awaiting finish of 4 more threads
2016-05-09 02:44:26,988: INFO: worker thread finished; awaiting finish of 3 more threads
2016-05-09 02:44:27,009: INFO: worker thread finished; awaiting finish of 2 more threads
2016-05-09 02:44:27,009: INFO: worker thread finished; awaiting finish of 1 more threads
2016-05-09 02:44:27,015: INFO: worker thread finished; awaiting finish of 0 more threads
2016-05-09 02:44:27,016: INFO: training on 10992637830 raw words (8908325719 effective words) took 15481.1s, 575434 effective words/s
2016-05-09 02:44:27,035: INFO: saving Word2Vec object under wiki.en.text.model, separately None
2016-05-09 02:44:27,035: INFO: storing numpy array &apos;syn1neg&apos; to wiki.en.text.model.syn1neg.npy
2016-05-09 02:44:35,705: INFO: not storing attribute syn0norm
2016-05-09 02:44:35,705: INFO: storing numpy array &apos;syn0&apos; to wiki.en.text.model.syn0.npy
2016-05-09 02:44:51,486: INFO: not storing attribute cum_table
2016-05-09 02:45:36,145: INFO: storing 2082765x100 projection weights into wiki.en.text.vector
</code></pre>&#x5F97;&#x5230;2G&#x7684;wiki.en.text.vector<pre><code>2082765 100
the 3.006923 0.197016 1.821211 0.577468 1.200783 -2.143173 -2.189645 2.280789 -0.500885 -0.029055 -1.866612 -3.537239 4.109666 2.681008 1.685016 1.846582 -4.121732 3.391886 -2.395795 -2.229913 2.567938 -2.872733 -3.175062 1.440397 0.989027 3.137877 -4.718245 -0.139462 -0.581739 -1.701072 -2.628166 0.748065 -0.704107 2.452936 -3.509637 -2.165193 3.200839 2.084164 -0.610669 -7.839321 2.376417 3.354800 1.399709 2.877409 -6.148983 -1.288296 -1.481419 1.514872 1.643264 -0.084024 -0.421993 1.965687 2.487681 -0.201347 1.095493 1.406878 -1.837678 -2.597307 -3.908334 -0.431535 1.659305 -1.325693 -1.448273 0.911582 -0.185698 -1.997922 -1.835947 -1.374178 2.162223 -1.981623 -1.046288 0.450714 0.966067 1.800625 -0.736050 -1.816792 -3.730878 -1.215927 0.920658 2.609656 -2.049159 -0.126193 1.389721 0.238941 1.667714 -1.431075 -3.288007 0.063848 -2.413035 0.897759 -3.347217 -2.927267 2.743397 -1.251601 -0.985500 -1.804784 -2.669296 -2.585315 2.603862 2.024329
</code></pre></li>
</ul>
<h5 id="online-training--resuming-training"><a name="online-training--resuming-training" class="plugin-anchor" href="#online-training--resuming-training"><i class="fa fa-link" aria-hidden="true"></i></a><a name="online-training--resuming-training" class="anchor-navigation-ex-anchor" href="#online-training--resuming-training"><i class="fa fa-link" aria-hidden="true"></i></a>Online training / Resuming training</h5>
<h2 id="multi-label"><a name="multi-label" class="plugin-anchor" href="#multi-label"><i class="fa fa-link" aria-hidden="true"></i></a><a name="multi-label" class="anchor-navigation-ex-anchor" href="#multi-label"><i class="fa fa-link" aria-hidden="true"></i></a>1.7. Multi-Label</h2>
<h3 id="binary-relevance-br"><a name="binary-relevance-br" class="plugin-anchor" href="#binary-relevance-br"><i class="fa fa-link" aria-hidden="true"></i></a><a name="binary-relevance-br" class="anchor-navigation-ex-anchor" href="#binary-relevance-br"><i class="fa fa-link" aria-hidden="true"></i></a>1.7.1. Binary Relevance (BR)</h3>
<h2 id="&#x5DE5;&#x5177;&#x7C7B;"><a name="&#x5DE5;&#x5177;&#x7C7B;" class="plugin-anchor" href="#&#x5DE5;&#x5177;&#x7C7B;"><i class="fa fa-link" aria-hidden="true"></i></a><a name="&#x5DE5;&#x5177;&#x7C7B;" class="anchor-navigation-ex-anchor" href="#&#x5DE5;&#x5177;&#x7C7B;"><i class="fa fa-link" aria-hidden="true"></i></a>1.8. &#x5DE5;&#x5177;&#x7C7B;</h2>
<h3 id="1documentpy"><a name="1documentpy" class="plugin-anchor" href="#1documentpy"><i class="fa fa-link" aria-hidden="true"></i></a><a name="1documentpy" class="anchor-navigation-ex-anchor" href="#1documentpy"><i class="fa fa-link" aria-hidden="true"></i></a>1.8.1. 1.Document.py</h3>
<h4 id="stopwords"><a name="stopwords" class="plugin-anchor" href="#stopwords"><i class="fa fa-link" aria-hidden="true"></i></a><a name="stopwords" class="anchor-navigation-ex-anchor" href="#stopwords"><i class="fa fa-link" aria-hidden="true"></i></a>stopwords</h4>
<pre><code class="lang-python"><span class="hljs-keyword">return</span> [w <span class="hljs-keyword">for</span> w <span class="hljs-keyword">in</span> self.get_all_words() <span class="hljs-keyword">if</span> w <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> STOPWORDS]
</code></pre>
<p>&#x3001;stemmer&#x5904;&#x7406;&#x4E4B;&#x540E;&#x5F97;&#x5230;&#x5173;&#x952E;&#x8BCD;</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_all_words</span><span class="hljs-params">(self)</span>:</span>
        <span class="hljs-string">&quot;&quot;&quot; Return all words tokenized, in lowercase and without punctuation &quot;&quot;&quot;</span>
        <span class="hljs-keyword">return</span> [w.lower() <span class="hljs-keyword">for</span> w <span class="hljs-keyword">in</span> word_tokenize(self.text)
                <span class="hljs-keyword">if</span> w <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> PUNCTUATION]
</code></pre>
<p>&#x5229;&#x7528;nltk&#x7684;tokenize:</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">word_tokenize</span><span class="hljs-params">(text, language=<span class="hljs-string">&apos;english&apos;</span>)</span>:</span>
    <span class="hljs-string">&quot;&quot;&quot;
    Return a tokenized copy of *text*,
    using NLTK&apos;s recommended word tokenizer
    (currently :class:`.TreebankWordTokenizer`
    along with :class:`.PunktSentenceTokenizer`
    for the specified language).

    :param text: text to split into sentences
    :param language: the model name in the Punkt corpus
    &quot;&quot;&quot;</span>
</code></pre>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="attention.html" class="navigation navigation-prev " aria-label="Previous page: Attention">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="alphago.html" class="navigation navigation-next " aria-label="Next page: AlphaGo">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"word2vec","level":"3.7.2","depth":2,"next":{"title":"AlphaGo","level":"3.7.3","depth":2,"path":"alphago.md","ref":"alphago.md","articles":[]},"previous":{"title":"Attention","level":"3.7.1","depth":2,"path":"attention.md","ref":"attention.md","articles":[]},"dir":"ltr"},"config":{"plugins":["mathjax-update-cdn","mermaid-gb3@2.1.0","expandable-chapters-small@^0.1.7","anchor-navigation-ex@0.1.8","todo@^0.1.3","anchors@^0.7.1","donate@^1.0.2"],"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"pluginsConfig":{"todo":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"donate":{"alipay":"http://static.zybuluo.com/sixijinling/3fnxywa4rs75f25kinu5ahnn/image_1cfuh8j65mc41k3q28cp431679.png","alipayText":"支付宝打赏","button":"赏","title":"","wechat":"http://static.zybuluo.com/sixijinling/3mhqbsdz9a24mrhdgj348e9x/image_1cfuoqam86g5197d1cnt12k211s823.png","wechatText":"微信打赏"},"fontsettings":{"theme":"white","family":"sans","size":2},"highlight":{},"mermaid-gb3":{},"anchor-navigation-ex":{"isRewritePageTitle":true,"isShowTocTitleIcon":true,"tocLevel1Icon":"fa fa-hand-o-right","tocLevel2Icon":"fa fa-hand-o-right","tocLevel3Icon":"fa fa-hand-o-right"},"expandable-chapters-small":{},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"mathjax-update-cdn":{"forceSVG":false,"version":"2.7.1"},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false},"anchors":{}},"theme":"default","pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"links":{"sidebar":{"Home":"http://rowl1ng.com"}},"gitbook":"*"},"file":{"path":"word2vec.md","mtime":"2018-07-24T03:43:46.077Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2019-07-13T14:45:23.881Z"},"basePath":".","book":{"language":""}});
        });
    </script>
</div>

        
    
    <script src="gitbook/gitbook.js"></script>
    <script src="gitbook/theme.js"></script>
    
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-mathjax-update-cdn/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-mermaid-gb3/book/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-donate/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    <script src="gitbook/gitbook-plugin-mermaid-gb3/mermaid/mermaid.min.js"></script>

    </body>
</html>

